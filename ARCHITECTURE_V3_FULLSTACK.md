# SAT-DISCOVERY V3.0 - äº”åŸŸå…¨æ ˆä¼ä¸šçº§æ¶æ„

## æ¦‚è¿°

ä»é™æ€å‰ç«¯å‡çº§åˆ°å®Œæ•´çš„ä¼ä¸šçº§å«æ˜Ÿæ•°æ®å¹³å°ï¼Œå®ç°äº”å¤§åŸŸæ¶æ„ã€‚

---

## ğŸ¯ æ¶æ„æ¼”è¿›

### V1.0 - é™æ€å‰ç«¯ (å·²å®Œæˆ âœ…)
- å¤šé¡µé¢é™æ€ç«™ç‚¹
- å®¢æˆ·ç«¯æœç´¢è¿‡æ»¤
- Vercel éƒ¨ç½²
- æ— åç«¯

### V2.0 - å®¢æˆ·ç«¯å…­åŸŸ (è§„åˆ’ä¸­ ğŸš§)
- å•é¡µåº”ç”¨ Workbench
- å®¢æˆ·ç«¯æ’ä»¶ç³»ç»Ÿ
- å‰ç«¯çŠ¶æ€ç®¡ç†
- ä»æ— åç«¯

### V3.0 - äº”åŸŸå…¨æ ˆ (æœ¬æ–‡æ¡£ ğŸ“‹)
- å®Œæ•´åç«¯æ¶æ„
- åˆ†å¸ƒå¼å¤„ç†
- ä¼ä¸šçº§èƒ½åŠ›
- å¯æ‰©å±•å¹³å°

---

## ğŸ›ï¸ äº”åŸŸæ¶æ„è¯¦è§£

### åŸŸ 1: æ•°æ®æ¥å…¥åŸŸ (Data Ingestion Domain)

#### èŒè´£
- æ‰€æœ‰æ•°æ®æºæ¥å…¥
- æ•°æ®æ ‡å‡†åŒ–
- å…ƒæ•°æ®ç´¢å¼•
- æ•°æ®æ³¨å†Œ

#### æ”¯æŒçš„æ•°æ®æº (17+)

**1. STAC ç³»åˆ—**
- å…¬å…± STAC Catalogs
- ç§æœ‰ STAC APIs
- EarthSearch
- Planetary Computer STAC
- Radiant MLHub STAC

**2. äº‘æœåŠ¡æä¾›å•†**
- AWS S3 (Sentinel-2, Landsat)
- Azure Blob Storage
- Google Cloud Storage
- Alibaba Cloud OSS

**3. ç©ºé—´æœºæ„**
- NASA CMR (Common Metadata Repository)
- ESA SciHub (Copernicus Sentinel)
- Copernicus Data Space
- JAXA Satellite Data
- NOAA Data Catalog
- USGS EarthExplorer
- EUMETSAT Data Store

**4. Web æœåŠ¡**
- WMS (Web Map Service)
- WMTS (Web Map Tile Service)
- OGC API - Features
- OGC API - Coverages
- OGC API - Processes

**5. ä¸“ä¸šå¹³å°**
- Sentinel Hub
- OpenTopography
- Planet Explorer API

**6. ä¼ ç»Ÿåè®®**
- FTP/SFTP æœåŠ¡å™¨
- HTTP/HTTPS ç›´æ¥ä¸‹è½½

#### æ¶æ„è®¾è®¡

```javascript
// æ•°æ®æºè¿æ¥å™¨æ¥å£
interface DataConnector {
  id: string;
  name: string;
  type: 'stac' | 'wms' | 's3' | 'ogc' | 'ftp' | 'api';
  
  // åˆå§‹åŒ–è¿æ¥
  async connect(config: ConnectorConfig): Promise<void>;
  
  // æœç´¢æ•°æ®
  async search(query: SearchQuery): Promise<SearchResult[]>;
  
  // è·å–å…ƒæ•°æ®
  async getMetadata(itemId: string): Promise<Metadata>;
  
  // ä¸‹è½½æ•°æ®
  async download(itemId: string, options: DownloadOptions): Promise<string>;
  
  // è·å–èƒ½åŠ›
  getCapabilities(): Capabilities;
  
  // éªŒè¯é…ç½®
  validateConfig(config: ConnectorConfig): ValidationResult;
}
```

#### æ•°æ®æ ‡å‡†åŒ–

æ‰€æœ‰æ•°æ®æºç»Ÿä¸€æ ‡å‡†åŒ–ä¸º:

```json
{
  "id": "unique-id",
  "collection": "collection-name",
  "geometry": {
    "type": "Polygon",
    "coordinates": [[...]]
  },
  "bbox": [minX, minY, maxX, maxY],
  "datetime": "2024-01-01T00:00:00Z",
  "properties": {
    "platform": "Sentinel-2A",
    "instrument": "MSI",
    "cloudCover": 10,
    "gsd": 10,
    "...": "..."
  },
  "assets": {
    "visual": { "href": "...", "type": "image/tiff" },
    "data": { "href": "...", "type": "application/x-netcdf" }
  },
  "links": [
    { "rel": "self", "href": "..." },
    { "rel": "parent", "href": "..." }
  ],
  "source": {
    "connector": "nasa-cmr",
    "originalId": "...",
    "ingestTime": "2024-01-01T00:00:00Z"
  }
}
```

#### å…ƒæ•°æ®ç´¢å¼•

ä½¿ç”¨ PostgreSQL + PostGIS:

```sql
CREATE TABLE data_items (
  id UUID PRIMARY KEY,
  collection VARCHAR(255),
  geometry GEOMETRY(Polygon, 4326),
  bbox BOX2D,
  datetime TIMESTAMPTZ,
  properties JSONB,
  assets JSONB,
  source JSONB,
  indexed_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_data_items_geometry ON data_items USING GIST(geometry);
CREATE INDEX idx_data_items_datetime ON data_items(datetime);
CREATE INDEX idx_data_items_properties ON data_items USING GIN(properties);
```

#### æ’ä»¶æ³¨å†Œæœºåˆ¶

```javascript
// è¿æ¥å™¨æ³¨å†Œå™¨
class ConnectorRegistry {
  private connectors: Map<string, DataConnector> = new Map();
  
  register(connector: DataConnector) {
    // éªŒè¯æ¥å£å®ç°
    this.validateConnector(connector);
    
    // æ³¨å†Œ
    this.connectors.set(connector.id, connector);
    
    // æŒä¹…åŒ–åˆ°æ•°æ®åº“
    this.persistConnector(connector);
    
    console.log(`âœ“ Registered connector: ${connector.name}`);
  }
  
  getConnector(id: string): DataConnector {
    return this.connectors.get(id);
  }
  
  listConnectors(): DataConnector[] {
    return Array.from(this.connectors.values());
  }
}
```

---

### åŸŸ 2: è½¨é“åŸŸ (Orbital Domain)

#### èŒè´£
- å«æ˜Ÿè½¨é“ä¼ æ’­
- è¿‡å¢ƒé¢„æµ‹
- AOI è¦†ç›–è®¡ç®—
- å¯è§æ€§åˆ†æ

#### å­èƒ½åŠ›

**1. TLE ç®¡ç†å™¨**
- è‡ªåŠ¨ä» Celestrak/Space-Track æ›´æ–°
- NORAD catalog æŸ¥è¯¢
- TLE ç‰ˆæœ¬ç®¡ç†
- å†å² TLE å­˜æ¡£

**2. SGP4 å¼•æ“**
- è½¨é“ä¼ æ’­è®¡ç®—
- å«æ˜Ÿä½ç½®é¢„æµ‹
- é€Ÿåº¦çŸ¢é‡è®¡ç®—
- é«˜åº¦/æ–¹ä½è§’è®¡ç®—

**3. è¿‡å¢ƒé¢„æµ‹å™¨**
- ç»™å®šåœ°ç‚¹çš„è¿‡å¢ƒæ—¶é—´
- æœ€å¤§ä»°è§’è®¡ç®—
- è¿‡å¢ƒæŒç»­æ—¶é—´
- ä¸Šå‡/ä¸‹é™æ–¹å‘

**4. è¦†ç›–ä¼°ç®—å™¨**
- AOI è¦†ç›–ç™¾åˆ†æ¯”
- Swath å¤šè¾¹å½¢è®¡ç®—
- é‡è®¿é¢‘ç‡åˆ†æ
- äº‘é‡å†å²è¶‹åŠ¿

**5. å¯è§†åŒ–å¼•æ“**
- åœ°é¢è½¨è¿¹ç»˜åˆ¶
- å®æ—¶ä½ç½®æ˜¾ç¤º
- è¦†ç›–åŒºåŸŸåŠ¨ç”»
- 3D è½¨é“è§†å›¾

#### æ•°æ®æº

æ”¯æŒä»ä»¥ä¸‹æºè·å– TLE:
- Celestrak (æ¨è)
- Space-Track (éœ€æ³¨å†Œ)
- N2YO API
- Open Orbital Data
- Heavens Above
- EUMETSAT ephemeris

#### æ¶æ„è®¾è®¡

```javascript
// TLE ç®¡ç†å™¨
class TLEManager {
  async updateTLE(satelliteId: string): Promise<TLE> {
    // ä»å¤šä¸ªæºè·å–æœ€æ–° TLE
    const sources = [
      'celestrak',
      'space-track',
      'n2yo'
    ];
    
    for (const source of sources) {
      try {
        const tle = await this.fetchTLE(satelliteId, source);
        if (tle) {
          // ä¿å­˜åˆ°æ•°æ®åº“
          await this.saveTLE(tle);
          return tle;
        }
      } catch (error) {
        console.error(`Failed to fetch from ${source}:`, error);
      }
    }
    
    throw new Error('Failed to update TLE from all sources');
  }
  
  async getTLE(satelliteId: string, epoch?: Date): Promise<TLE> {
    // è·å–æŒ‡å®šæ—¶é—´çš„ TLE (å†å²æˆ–æœ€æ–°)
    if (epoch) {
      return this.getHistoricalTLE(satelliteId, epoch);
    }
    return this.getLatestTLE(satelliteId);
  }
}

// è¿‡å¢ƒé¢„æµ‹å™¨
class PassPredictor {
  async predictPasses(
    satelliteId: string,
    location: Location,
    startTime: Date,
    endTime: Date,
    minElevation: number = 10
  ): Promise<Pass[]> {
    const tle = await TLEManager.getTLE(satelliteId);
    const passes: Pass[] = [];
    
    // ä½¿ç”¨ SGP4 ä¼ æ’­
    let currentTime = startTime;
    while (currentTime < endTime) {
      const pass = this.calculatePass(tle, location, currentTime, minElevation);
      if (pass) {
        passes.push(pass);
        currentTime = pass.endTime;
      }
      currentTime = new Date(currentTime.getTime() + 60000); // +1åˆ†é’Ÿ
    }
    
    return passes;
  }
  
  private calculatePass(
    tle: TLE,
    location: Location,
    startTime: Date,
    minElevation: number
  ): Pass | null {
    // SGP4 è½¨é“ä¼ æ’­è®¡ç®—
    // è®¡ç®—ä»°è§’ã€æ–¹ä½è§’ã€è·ç¦»
    // è¿”å›è¿‡å¢ƒä¿¡æ¯
  }
}

// AOI è¦†ç›–è®¡ç®—å™¨
class CoverageCalculator {
  async calculateCoverage(
    satelliteId: string,
    aoi: Polygon,
    timeRange: TimeRange
  ): Promise<CoverageResult> {
    const passes = await PassPredictor.predictPasses(
      satelliteId,
      aoi.centroid,
      timeRange.start,
      timeRange.end
    );
    
    let totalCoverage = 0;
    const coveragePolygons: Polygon[] = [];
    
    for (const pass of passes) {
      // è®¡ç®— swath å¤šè¾¹å½¢
      const swath = this.calculateSwath(satelliteId, pass);
      
      // è®¡ç®—ä¸ AOI çš„äº¤é›†
      const intersection = turf.intersect(aoi, swath);
      if (intersection) {
        totalCoverage += turf.area(intersection);
        coveragePolygons.push(intersection);
      }
    }
    
    return {
      coveragePercentage: (totalCoverage / turf.area(aoi)) * 100,
      passCount: passes.length,
      coveragePolygons
    };
  }
}
```

#### æ•°æ®åº“è®¾è®¡

```sql
CREATE TABLE satellite_catalog (
  norad_id INTEGER PRIMARY KEY,
  name VARCHAR(255),
  international_designator VARCHAR(20),
  launch_date DATE,
  platform_type VARCHAR(50),
  sensor_type VARCHAR(50),
  swath_width_km FLOAT,
  revisit_days INTEGER
);

CREATE TABLE tle_history (
  id SERIAL PRIMARY KEY,
  norad_id INTEGER REFERENCES satellite_catalog(norad_id),
  epoch TIMESTAMPTZ,
  line1 TEXT,
  line2 TEXT,
  source VARCHAR(50),
  fetched_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(norad_id, epoch)
);

CREATE INDEX idx_tle_history_epoch ON tle_history(norad_id, epoch DESC);
```

---

### åŸŸ 3: å¤„ç†åŸŸ (Processing Domain)

#### èŒè´£
- ç®—æ³•æ‰§è¡Œ
- æ•°æ®è½¬æ¢
- åˆ†æè®¡ç®—

#### ç®—æ³•ç±»å‹

**å…‰è°±æŒ‡æ•°**
- NDVI (Normalized Difference Vegetation Index)
- NDWI (Normalized Difference Water Index)
- NDBI (Normalized Difference Built-up Index)
- EVI (Enhanced Vegetation Index)
- SAVI (Soil Adjusted Vegetation Index)

**SAR å¤„ç†**
- SAR Coherence
- Speckle Filtering
- Backscatter Analysis
- InSAR Processing
- Polarimetric Decomposition

**DEM å·¥å…·**
- Slope/Aspect
- Hillshade
- Contours
- Viewshed Analysis
- Terrain Correction

**å˜åŒ–æ£€æµ‹**
- Image Differencing
- PCA (Principal Component Analysis)
- MAD (Multivariate Alteration Detection)
- Time Series Analysis

**å›¾åƒå¤„ç†**
- Cloud Masking
- Atmospheric Correction
- Pansharpening
- Super Resolution (AI)
- Mosaic & Tiling

**ç©ºé—´åˆ†æ**
- AOI Clipping
- Zonal Statistics
- Buffer Analysis
- Overlay Operations

**æ—¶é—´åºåˆ—**
- Time Series Aggregation
- Trend Analysis
- Anomaly Detection
- Seasonal Decomposition

**æœºå™¨å­¦ä¹ **
- Land Cover Classification
- Object Detection
- Segmentation
- Feature Extraction

#### ç®—æ³•æ’ä»¶æ¥å£

```javascript
interface ProcessingAlgorithm {
  id: string;
  name: string;
  version: string;
  category: 'spectral' | 'sar' | 'dem' | 'change' | 'ml';
  
  // è¾“å…¥è¾“å‡ºå®šä¹‰
  inputs: InputSchema[];
  outputs: OutputSchema[];
  parameters: ParameterSchema[];
  
  // æ‰§è¡Œç®—æ³•
  async process(
    inputs: Map<string, any>,
    parameters: Map<string, any>
  ): Promise<Map<string, any>>;
  
  // éªŒè¯è¾“å…¥
  validateInputs(inputs: Map<string, any>): ValidationResult;
  
  // é¢„ä¼°èµ„æºéœ€æ±‚
  estimateResources(inputs: Map<string, any>): ResourceEstimate;
  
  // è·å–æ–‡æ¡£
  getDocumentation(): Documentation;
}
```

#### æ‰§è¡Œç¯å¢ƒ

**é€‰é¡¹ 1: WebAssembly Sandbox (å®¢æˆ·ç«¯)**
```javascript
// ä½¿ç”¨ WASM åœ¨æµè§ˆå™¨ä¸­æ‰§è¡Œ
class WasmAlgorithmRunner {
  async loadAlgorithm(algorithmId: string): Promise<WasmModule> {
    const wasmFile = await fetch(`/algorithms/${algorithmId}.wasm`);
    const wasmModule = await WebAssembly.compile(await wasmFile.arrayBuffer());
    return WebAssembly.instantiate(wasmModule);
  }
  
  async execute(
    algorithm: WasmModule,
    inputs: any,
    parameters: any
  ): Promise<any> {
    // è°ƒç”¨ WASM å‡½æ•°
    return algorithm.exports.process(inputs, parameters);
  }
}
```

**é€‰é¡¹ 2: åç«¯æœåŠ¡ (æ¨è)**
```javascript
// Node.js åç«¯ API
app.post('/api/v1/process/:algorithmId', async (req, res) => {
  const { algorithmId } = req.params;
  const { inputs, parameters } = req.body;
  
  // åˆ›å»ºä»»åŠ¡
  const task = await TaskQueue.enqueue({
    type: 'processing',
    algorithmId,
    inputs,
    parameters,
    userId: req.user.id
  });
  
  // å¼‚æ­¥å¤„ç†
  ProcessingWorker.process(task);
  
  // è¿”å›ä»»åŠ¡ ID
  res.json({
    taskId: task.id,
    status: 'queued',
    estimatedTime: task.estimatedTime
  });
});
```

**é€‰é¡¹ 3: Serverless Function**
```javascript
// AWS Lambda / Vercel Function
export default async function handler(req, res) {
  const { algorithmId, inputs, parameters } = req.body;
  
  // åŠ è½½ç®—æ³•
  const algorithm = await AlgorithmRegistry.get(algorithmId);
  
  // æ‰§è¡Œ
  const result = await algorithm.process(inputs, parameters);
  
  // ä¿å­˜ç»“æœåˆ° S3
  await saveResult(result);
  
  res.json({ result });
}
```

#### èµ„æºç®¡ç†

```javascript
class ResourceManager {
  // æ£€æŸ¥èµ„æºå¯ç”¨æ€§
  async checkAvailability(estimate: ResourceEstimate): Promise<boolean> {
    const available = await this.getAvailableResources();
    return (
      available.cpu >= estimate.cpu &&
      available.memory >= estimate.memory &&
      available.storage >= estimate.storage
    );
  }
  
  // åˆ†é…èµ„æº
  async allocate(taskId: string, resources: Resources): Promise<void> {
    await this.reserveResources(taskId, resources);
  }
  
  // é‡Šæ”¾èµ„æº
  async release(taskId: string): Promise<void> {
    await this.freeResources(taskId);
  }
}
```

---

### åŸŸ 4: è°ƒåº¦åŸŸ (Orchestration Domain)

#### èŒè´£
- ä»»åŠ¡ç®¡ç†
- èµ„æºåˆ†é…
- çŠ¶æ€æ§åˆ¶

#### å­èƒ½åŠ›

**1. ä»»åŠ¡é˜Ÿåˆ—**
- ä¼˜å…ˆçº§é˜Ÿåˆ—
- FIFO/LIFO
- å»¶è¿Ÿæ‰§è¡Œ
- å®šæ—¶ä»»åŠ¡

**2. ä»»åŠ¡è°ƒåº¦å™¨**
- èµ„æºè°ƒåº¦
- è´Ÿè½½å‡è¡¡
- å¹¶å‘æ§åˆ¶
- ä¾èµ–ç®¡ç†

**3. é‡è¯•ç®¡ç†å™¨**
- å¤±è´¥é‡è¯•
- æŒ‡æ•°é€€é¿
- æœ€å¤§é‡è¯•æ¬¡æ•°
- æ­»ä¿¡é˜Ÿåˆ—

**4. æ—¥å¿—ç³»ç»Ÿ**
- ç»“æ„åŒ–æ—¥å¿—
- æ—¥å¿—èšåˆ
- å®æ—¶æ—¥å¿—æµ
- æ—¥å¿—æŸ¥è¯¢

**5. èµ„æºåˆ†é…å™¨**
- CPU åˆ†é…
- å†…å­˜ç®¡ç†
- å­˜å‚¨é…é¢
- ç½‘ç»œå¸¦å®½

#### æ¶æ„è®¾è®¡

```javascript
// ä»»åŠ¡é˜Ÿåˆ—
class TaskQueue {
  private redis: Redis;
  
  async enqueue(task: Task): Promise<Task> {
    // ç”Ÿæˆä»»åŠ¡ ID
    task.id = uuidv4();
    task.status = 'queued';
    task.queuedAt = new Date();
    
    // è®¡ç®—ä¼˜å…ˆçº§
    const priority = this.calculatePriority(task);
    
    // æ·»åŠ åˆ° Redis é˜Ÿåˆ—
    await this.redis.zadd('task_queue', priority, JSON.stringify(task));
    
    // ä¿å­˜åˆ°æ•°æ®åº“
    await this.saveTask(task);
    
    // è§¦å‘äº‹ä»¶
    this.emit('task:queued', task);
    
    return task;
  }
  
  async dequeue(): Promise<Task | null> {
    // ä» Redis è·å–æœ€é«˜ä¼˜å…ˆçº§ä»»åŠ¡
    const tasks = await this.redis.zpopmax('task_queue', 1);
    if (tasks.length === 0) return null;
    
    const task = JSON.parse(tasks[0]);
    task.status = 'running';
    task.startedAt = new Date();
    
    await this.updateTask(task);
    
    return task;
  }
}

// ä»»åŠ¡è°ƒåº¦å™¨
class JobScheduler {
  private workers: Worker[] = [];
  private maxWorkers: number = 10;
  
  async start(): Promise<void> {
    // å¯åŠ¨å·¥ä½œè¿›ç¨‹
    for (let i = 0; i < this.maxWorkers; i++) {
      const worker = new Worker();
      worker.on('task:completed', (task) => this.handleCompletion(task));
      worker.on('task:failed', (task, error) => this.handleFailure(task, error));
      worker.start();
      this.workers.push(worker);
    }
    
    console.log(`âœ“ Started ${this.maxWorkers} workers`);
  }
  
  private async handleCompletion(task: Task): Promise<void> {
    task.status = 'completed';
    task.completedAt = new Date();
    await TaskQueue.updateTask(task);
    
    // é‡Šæ”¾èµ„æº
    await ResourceManager.release(task.id);
    
    // æ‰§è¡Œä¾èµ–ä»»åŠ¡
    await this.executeDependents(task);
  }
  
  private async handleFailure(task: Task, error: Error): Promise<void> {
    task.attempts = (task.attempts || 0) + 1;
    
    if (task.attempts < task.maxRetries) {
      // é‡è¯•
      await RetryManager.scheduleRetry(task);
    } else {
      // æ ‡è®°ä¸ºå¤±è´¥
      task.status = 'failed';
      task.error = error.message;
      await TaskQueue.updateTask(task);
      
      // ç§»åˆ°æ­»ä¿¡é˜Ÿåˆ—
      await this.moveToDeadLetter(task);
    }
  }
}

// é‡è¯•ç®¡ç†å™¨
class RetryManager {
  async scheduleRetry(task: Task): Promise<void> {
    // è®¡ç®—å»¶è¿Ÿæ—¶é—´ (æŒ‡æ•°é€€é¿)
    const delay = Math.pow(2, task.attempts) * 1000; // 2^n ç§’
    
    // é‡æ–°å…¥é˜Ÿ
    task.status = 'retry_scheduled';
    task.retryAt = new Date(Date.now() + delay);
    await TaskQueue.updateTask(task);
    
    // ä½¿ç”¨ Redis å»¶è¿Ÿé˜Ÿåˆ—
    await this.redis.zadd(
      'retry_queue',
      task.retryAt.getTime(),
      JSON.stringify(task)
    );
  }
}
```

#### æ•°æ®åº“è®¾è®¡

```sql
CREATE TABLE tasks (
  id UUID PRIMARY KEY,
  type VARCHAR(50),
  status VARCHAR(20),
  priority INTEGER,
  
  -- é…ç½®
  config JSONB,
  
  -- èµ„æº
  resources JSONB,
  
  -- æ—¶é—´æˆ³
  queued_at TIMESTAMPTZ,
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ,
  
  -- é‡è¯•
  attempts INTEGER DEFAULT 0,
  max_retries INTEGER DEFAULT 3,
  retry_at TIMESTAMPTZ,
  
  -- ç»“æœ
  result JSONB,
  error TEXT,
  
  -- ç”¨æˆ·
  user_id UUID,
  
  CONSTRAINT chk_status CHECK (
    status IN ('queued', 'running', 'completed', 'failed', 'retry_scheduled', 'cancelled')
  )
);

CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_priority ON tasks(priority DESC) WHERE status = 'queued';
CREATE INDEX idx_tasks_retry_at ON tasks(retry_at) WHERE status = 'retry_scheduled';

CREATE TABLE task_logs (
  id SERIAL PRIMARY KEY,
  task_id UUID REFERENCES tasks(id),
  timestamp TIMESTAMPTZ DEFAULT NOW(),
  level VARCHAR(10),
  message TEXT,
  metadata JSONB
);

CREATE INDEX idx_task_logs_task_id ON task_logs(task_id, timestamp DESC);
```

---

### åŸŸ 5: è®¿é—®åŸŸ (Access Domain)

#### èŒè´£
- UI ç•Œé¢
- API ç½‘å…³
- æ’ä»¶æ³¨å†Œ
- æƒé™æ§åˆ¶

#### å­èƒ½åŠ›

**1. Web UI**
- ç»Ÿä¸€ Workbench
- åœ°å›¾å®¢æˆ·ç«¯
- ä»»åŠ¡ç›‘æ§é¢æ¿
- æ•°æ®æµè§ˆå™¨

**2. API Gateway**
- RESTful API
- GraphQL API
- WebSocket API
- gRPC API (å†…éƒ¨)

**3. æ’ä»¶æ³¨å†Œè¡¨**
- æ’ä»¶å‘å¸ƒ
- ç‰ˆæœ¬ç®¡ç†
- ä¾èµ–è§£æ
- æ’ä»¶å¸‚åœº

**4. æƒé™æ§åˆ¶**
- ç”¨æˆ·è®¤è¯
- API Key ç®¡ç†
- æƒé™å±‚çº§
- RBAC (Role-Based Access Control)

**5. SDK ç”Ÿæˆå™¨**
- JavaScript SDK
- Python SDK
- CLI å·¥å…·
- API æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ

#### API ç½‘å…³è®¾è®¡

```javascript
// API Gateway
class APIGateway {
  private rateLimiter: RateLimiter;
  private authenticator: Authenticator;
  private router: Router;
  
  async handleRequest(req: Request, res: Response): Promise<void> {
    try {
      // 1. è®¤è¯
      const user = await this.authenticator.authenticate(req);
      if (!user) {
        return res.status(401).json({ error: 'Unauthorized' });
      }
      
      // 2. é™æµ
      const allowed = await this.rateLimiter.check(user.id);
      if (!allowed) {
        return res.status(429).json({ error: 'Rate limit exceeded' });
      }
      
      // 3. æƒé™æ£€æŸ¥
      const hasPermission = await this.checkPermission(user, req.path, req.method);
      if (!hasPermission) {
        return res.status(403).json({ error: 'Forbidden' });
      }
      
      // 4. è·¯ç”±åˆ°ç›¸åº”æœåŠ¡
      const result = await this.router.route(req);
      
      // 5. è®°å½•ä½¿ç”¨ç»Ÿè®¡
      await this.recordUsage(user, req);
      
      // 6. è¿”å›ç»“æœ
      res.json(result);
      
    } catch (error) {
      console.error('API Gateway error:', error);
      res.status(500).json({ error: 'Internal server error' });
    }
  }
}

// é™æµå™¨
class RateLimiter {
  private redis: Redis;
  
  async check(userId: string, limit: number = 100): Promise<boolean> {
    const key = `rate_limit:${userId}:${Math.floor(Date.now() / 60000)}`;
    const count = await this.redis.incr(key);
    
    if (count === 1) {
      await this.redis.expire(key, 60); // 1åˆ†é’Ÿè¿‡æœŸ
    }
    
    return count <= limit;
  }
}

// API Key ç®¡ç†
class APIKeyManager {
  async createKey(userId: string, permissions: string[]): Promise<APIKey> {
    const key = this.generateKey();
    const apiKey = {
      id: uuidv4(),
      key: await this.hashKey(key),
      userId,
      permissions,
      createdAt: new Date(),
      expiresAt: new Date(Date.now() + 365 * 24 * 60 * 60 * 1000), // 1å¹´
      isActive: true
    };
    
    await this.saveAPIKey(apiKey);
    
    return { ...apiKey, key }; // åªè¿”å›ä¸€æ¬¡æ˜æ–‡ key
  }
  
  async validateKey(key: string): Promise<APIKey | null> {
    const hashedKey = await this.hashKey(key);
    const apiKey = await this.findByHash(hashedKey);
    
    if (!apiKey || !apiKey.isActive || apiKey.expiresAt < new Date()) {
      return null;
    }
    
    return apiKey;
  }
}
```

#### æ’ä»¶æ³¨å†Œè¡¨

```javascript
class PluginRegistry {
  async publish(plugin: Plugin): Promise<void> {
    // 1. éªŒè¯æ’ä»¶
    await this.validatePlugin(plugin);
    
    // 2. æ£€æŸ¥ç‰ˆæœ¬å†²çª
    const existing = await this.findPlugin(plugin.id, plugin.version);
    if (existing) {
      throw new Error('Plugin version already exists');
    }
    
    // 3. è§£æä¾èµ–
    await this.resolveDependencies(plugin);
    
    // 4. ä¿å­˜åˆ°æ•°æ®åº“
    await this.savePlugin(plugin);
    
    // 5. ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
    await this.uploadPluginFiles(plugin);
    
    // 6. è§¦å‘äº‹ä»¶
    this.emit('plugin:published', plugin);
  }
  
  async install(pluginId: string, version: string, userId: string): Promise<void> {
    // 1. è·å–æ’ä»¶
    const plugin = await this.findPlugin(pluginId, version);
    if (!plugin) {
      throw new Error('Plugin not found');
    }
    
    // 2. æ£€æŸ¥æƒé™
    await this.checkInstallPermission(userId, plugin);
    
    // 3. å®‰è£…ä¾èµ–
    for (const dep of plugin.dependencies) {
      await this.install(dep.id, dep.version, userId);
    }
    
    // 4. ä¸‹è½½æ’ä»¶æ–‡ä»¶
    await this.downloadPluginFiles(plugin);
    
    // 5. æ¿€æ´»æ’ä»¶
    await this.activatePlugin(pluginId, userId);
  }
}
```

---

## ğŸ”§ æŠ€æœ¯æ ˆ

### åç«¯

**æ ¸å¿ƒæœåŠ¡**
- Node.js (Express / Fastify)
- Python (FastAPI) - ç”¨äºç§‘å­¦è®¡ç®—
- TypeScript - ç±»å‹å®‰å…¨

**æ•°æ®åº“**
- PostgreSQL 14+ (ä¸»æ•°æ®åº“)
- PostGIS (ç©ºé—´æ‰©å±•)
- Redis (ç¼“å­˜ + é˜Ÿåˆ—)
- Elasticsearch (æ—¥å¿— + æœç´¢)

**æ¶ˆæ¯é˜Ÿåˆ—**
- Bull (Redis-based)
- RabbitMQ (å¯é€‰)
- Apache Kafka (å¤§è§„æ¨¡)

**å¯¹è±¡å­˜å‚¨**
- MinIO (è‡ªæ‰˜ç®¡)
- AWS S3
- Azure Blob

**è½¨é“è®¡ç®—**
- satellite.js (SGP4)
- Python skyfield
- GMAT (é«˜ç²¾åº¦)

**å¤„ç†å¼•æ“**
- GDAL (åœ°ç†æ•°æ®)
- Rasterio (æ …æ ¼)
- NumPy / SciPy
- TensorFlow / PyTorch (ML)

### å®¹å™¨åŒ–

```yaml
# docker-compose.yml
version: '3.8'

services:
  # API Gateway
  gateway:
    build: ./services/gateway
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
  
  # æ•°æ®æ¥å…¥æœåŠ¡
  data-ingestion:
    build: ./services/data-ingestion
    environment:
      - DATABASE_URL=postgresql://...
    depends_on:
      - postgres
  
  # è½¨é“æœåŠ¡
  orbital:
    build: ./services/orbital
    environment:
      - DATABASE_URL=postgresql://...
  
  # å¤„ç†æœåŠ¡
  processing:
    build: ./services/processing
    deploy:
      replicas: 3
    environment:
      - REDIS_URL=redis://redis:6379
  
  # ä»»åŠ¡è°ƒåº¦
  scheduler:
    build: ./services/scheduler
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://redis:6379
  
  # æ•°æ®åº“
  postgres:
    image: postgis/postgis:14-3.3
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=sat_discovery
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=secret
  
  # ç¼“å­˜/é˜Ÿåˆ—
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
  
  # å¯¹è±¡å­˜å‚¨
  minio:
    image: minio/minio
    volumes:
      - minio_data:/data
    command: server /data
    ports:
      - "9000:9000"

volumes:
  postgres_data:
  redis_data:
  minio_data:
```

### Kubernetes éƒ¨ç½²

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gateway
spec:
  replicas: 3
  selector:
    matchLabels:
      app: gateway
  template:
    metadata:
      labels:
        app: gateway
    spec:
      containers:
      - name: gateway
        image: sat-discovery/gateway:latest
        ports:
        - containerPort: 3000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: gateway
spec:
  selector:
    app: gateway
  ports:
  - port: 80
    targetPort: 3000
  type: LoadBalancer
```

---

## ğŸ“Š é¡¹ç›®ç›®å½•ç»“æ„

```
sat-discovery-platform/
â”œâ”€â”€ frontend/                    # å‰ç«¯ (V1/V2)
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                     # åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ gateway/            # API Gateway
â”‚   â”‚   â”œâ”€â”€ data-ingestion/     # æ•°æ®æ¥å…¥
â”‚   â”‚   â”œâ”€â”€ orbital/            # è½¨é“æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ processing/         # å¤„ç†æœåŠ¡
â”‚   â”‚   â””â”€â”€ scheduler/          # ä»»åŠ¡è°ƒåº¦
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/                 # å…±äº«åº“
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ plugins/                     # æ’ä»¶
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ stac/
â”‚   â”‚   â”œâ”€â”€ wms/
â”‚   â”‚   â””â”€â”€ s3/
â”‚   â”‚
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ ndvi/
â”‚   â”‚   â”œâ”€â”€ sar/
â”‚   â”‚   â””â”€â”€ ml/
â”‚   â”‚
â”‚   â””â”€â”€ visualizers/
â”‚
â”œâ”€â”€ infrastructure/              # åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ ansible/
â”‚
â”œâ”€â”€ docs/                        # æ–‡æ¡£
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ guides/
â”‚
â””â”€â”€ tests/                       # æµ‹è¯•
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: åŸºç¡€è®¾æ–½ (4 å‘¨)

**Week 1-2: æ•°æ®åº“ + åç«¯æ¡†æ¶**
- [ ] PostgreSQL + PostGIS è®¾ç½®
- [ ] Redis è®¾ç½®
- [ ] API Gateway éª¨æ¶
- [ ] è®¤è¯/æˆæƒç³»ç»Ÿ

**Week 3-4: æ•°æ®æ¥å…¥åŸŸ**
- [ ] è¿æ¥å™¨æ¥å£å®šä¹‰
- [ ] STAC Connector å®ç°
- [ ] NASA CMR Connector å®ç°
- [ ] æ•°æ®æ ‡å‡†åŒ–å¼•æ“
- [ ] å…ƒæ•°æ®ç´¢å¼•

### Phase 2: è½¨é“åŸŸ (3 å‘¨)

**Week 5-6: TLE ç®¡ç† + SGP4**
- [ ] TLE ç®¡ç†å™¨
- [ ] Celestrak é›†æˆ
- [ ] SGP4 å¼•æ“é›†æˆ
- [ ] è½¨é“ä¼ æ’­ API

**Week 7: è¿‡å¢ƒé¢„æµ‹**
- [ ] Pass é¢„æµ‹å™¨
- [ ] AOI è¦†ç›–è®¡ç®—
- [ ] å¯è§†åŒ– API

### Phase 3: å¤„ç†åŸŸ (4 å‘¨)

**Week 8-9: ç®—æ³•æ¡†æ¶**
- [ ] ç®—æ³•æ¥å£å®šä¹‰
- [ ] ç®—æ³•æ³¨å†Œå™¨
- [ ] æ‰§è¡Œå¼•æ“ (åç«¯)
- [ ] èµ„æºç®¡ç†å™¨

**Week 10-11: æ ¸å¿ƒç®—æ³•**
- [ ] NDVI/NDWI å®ç°
- [ ] SAR å¤„ç†åŸºç¡€
- [ ] DEM å·¥å…·
- [ ] æ—¶é—´åºåˆ—åˆ†æ

### Phase 4: è°ƒåº¦åŸŸ (3 å‘¨)

**Week 12: ä»»åŠ¡é˜Ÿåˆ—**
- [ ] Task Queue å®ç°
- [ ] Job Scheduler
- [ ] Worker è¿›ç¨‹

**Week 13-14: ç›‘æ§ + é‡è¯•**
- [ ] é‡è¯•ç®¡ç†å™¨
- [ ] æ—¥å¿—ç³»ç»Ÿ
- [ ] ç›‘æ§é¢æ¿

### Phase 5: è®¿é—®åŸŸ (2 å‘¨)

**Week 15: API + SDK**
- [ ] RESTful API å®Œå–„
- [ ] JavaScript SDK
- [ ] Python SDK
- [ ] CLI å·¥å…·

**Week 16: æ’ä»¶ç³»ç»Ÿ**
- [ ] æ’ä»¶æ³¨å†Œè¡¨
- [ ] æ’ä»¶å¸‚åœº UI
- [ ] æ’ä»¶å®‰è£…å™¨

---

## âœ… äº¤ä»˜æ ‡å‡†

### åŠŸèƒ½å®Œæ•´æ€§

1. âœ… è‡³å°‘ 10 ä¸ªæ•°æ®æºè¿æ¥å™¨å¯ç”¨
2. âœ… è½¨é“é¢„æµ‹å‡†ç¡®ç‡ > 95%
3. âœ… è‡³å°‘ 5 ç§å¤„ç†ç®—æ³•å¯æ‰§è¡Œ
4. âœ… ä»»åŠ¡é˜Ÿåˆ—æ”¯æŒ 1000+ å¹¶å‘
5. âœ… API å“åº”æ—¶é—´ < 200ms (p95)

### æ€§èƒ½æŒ‡æ ‡

- æ•°æ®ç´¢å¼•é€Ÿåº¦: > 10k items/min
- è½¨é“è®¡ç®—: < 100ms/pass
- ç®—æ³•æ‰§è¡Œ: æ ¹æ®ç®—æ³•å¤æ‚åº¦
- ä»»åŠ¡åå: > 100 tasks/min

### å¯é æ€§

- æœåŠ¡å¯ç”¨æ€§: > 99.9%
- æ•°æ®ä¸€è‡´æ€§: å¼ºä¸€è‡´æ€§
- å¤±è´¥é‡è¯•æˆåŠŸç‡: > 90%

### å®‰å…¨æ€§

- æ‰€æœ‰ API éœ€è¦è®¤è¯
- æ•æ„Ÿæ•°æ®åŠ å¯†å­˜å‚¨
- å®¡è®¡æ—¥å¿—å®Œæ•´
- GDPR åˆè§„

---

## ğŸ’° æˆæœ¬ä¼°ç®—

### å¼€å‘æˆæœ¬

- å…¨æ ˆå·¥ç¨‹å¸ˆ x 2: 16 å‘¨
- åç«¯å·¥ç¨‹å¸ˆ x 2: 16 å‘¨
- DevOps å·¥ç¨‹å¸ˆ x 1: 8 å‘¨
- QA å·¥ç¨‹å¸ˆ x 1: 4 å‘¨

### è¿è¥æˆæœ¬ (æœˆ)

**åŸºç¡€ç‰ˆ (1000 ç”¨æˆ·)**
- æ•°æ®åº“: $100 (RDS)
- ç¼“å­˜: $50 (ElastiCache)
- è®¡ç®—: $200 (EC2/ECS)
- å­˜å‚¨: $100 (S3)
- **æ€»è®¡: ~$450/æœˆ**

**ä¼ä¸šç‰ˆ (10000 ç”¨æˆ·)**
- æ•°æ®åº“: $500
- ç¼“å­˜: $200
- è®¡ç®—: $1000
- å­˜å‚¨: $500
- CDN: $200
- **æ€»è®¡: ~$2400/æœˆ**

---

## ğŸ¯ MVP èŒƒå›´

å¦‚æœéœ€è¦å¿«é€ŸéªŒè¯ï¼ŒMVP åº”åŒ…æ‹¬:

### æœ€å°å¯è¡ŒåŸŸ

**1. æ•°æ®æ¥å…¥åŸŸ (ç®€åŒ–)**
- STAC Connector (2-3 ä¸ªå…¬å…±æº)
- åŸºç¡€å…ƒæ•°æ®ç´¢å¼•

**2. è½¨é“åŸŸ (ç®€åŒ–)**
- TLE æ›´æ–° (Celestrak)
- ç®€å•è¿‡å¢ƒé¢„æµ‹
- æ— äº‘é‡åˆ†æ

**3. å¤„ç†åŸŸ (ç®€åŒ–)**
- NDVI ç®—æ³• (ä»…æ­¤ä¸€ä¸ª)
- åŒæ­¥æ‰§è¡Œ (æ— é˜Ÿåˆ—)

**4. è°ƒåº¦åŸŸ (ç®€åŒ–)**
- ç®€å•ä»»åŠ¡è¡¨
- æ— é‡è¯•
- åŸºç¡€æ—¥å¿—

**5. è®¿é—®åŸŸ (ç®€åŒ–)**
- åŸºç¡€ API
- ç®€å•è®¤è¯
- æ—  SDK

### MVP æ—¶é—´çº¿

- **4-6 å‘¨** å¼€å‘
- **2 å‘¨** æµ‹è¯•
- **æ€»è®¡: 6-8 å‘¨**

---

## ğŸ“ æ€»ç»“

ä»é™æ€ç«™ç‚¹åˆ°ä¼ä¸šçº§äº”åŸŸå¹³å°æ˜¯ä¸€ä¸ªé‡å¤§çš„æ¶æ„å‡çº§,éœ€è¦:

1. **åç«¯åŸºç¡€è®¾æ–½** - Node.js + Python + PostgreSQL + Redis
2. **å®¹å™¨åŒ–éƒ¨ç½²** - Docker + Kubernetes
3. **åˆ†å¸ƒå¼æ¶æ„** - å¾®æœåŠ¡ + æ¶ˆæ¯é˜Ÿåˆ—
4. **ä¸“ä¸šå·¥å…·** - GDAL + satellite.js + ç§‘å­¦è®¡ç®—åº“
5. **å›¢é˜Ÿæ‰©å±•** - å…¨æ ˆ/åç«¯/DevOps å·¥ç¨‹å¸ˆ

**å»ºè®®**:
- ä¿æŒ V1.0 å¯éƒ¨ç½² (ç«‹å³ä¸Šçº¿)
- V3.0 åˆ†é˜¶æ®µå¼€å‘ (16å‘¨å®Œæ•´ç‰ˆ æˆ– 6-8å‘¨ MVP)
- è€ƒè™‘æ··åˆæ¶æ„ (å‰ç«¯ Vercel + åç«¯äº‘æœåŠ¡)

---

**æ–‡æ¡£ç‰ˆæœ¬**: V3.0 Architecture  
**åˆ›å»ºæ—¥æœŸ**: 2026-02-19  
**çŠ¶æ€**: è§„åˆ’ä¸­
